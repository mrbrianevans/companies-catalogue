name: Lakehouse load jobs
on:
  schedule:
    - cron: '0 6 * * *'
  workflow_dispatch:

env:
  SINK_BUCKET: ${{ secrets.SINK_BUCKET || vars.SINK_BUCKET }}
  SNAPSHOT_BUCKET: ${{ secrets.SNAPSHOT_BUCKET || vars.SNAPSHOT_BUCKET }}
  LAKE_BUCKET: ${{ secrets.LAKE_BUCKET || vars.LAKE_BUCKET }}
  S3_ENDPOINT: ${{ secrets.S3_ENDPOINT || vars.S3_ENDPOINT }}
  S3_ACCESS_KEY_ID: ${{ secrets.S3_ACCESS_KEY_ID }}
  S3_SECRET_ACCESS_KEY: ${{ secrets.S3_SECRET_ACCESS_KEY }}
  S3_REGION: ${{ secrets.S3_REGION || vars.S3_REGION }}
  STREAM_KEY: ${{ secrets.STREAM_KEY }}

concurrency: lakehouse

jobs:
  capture-streams:
    name: Capture event streams
    runs-on: ubuntu-latest

    strategy:
      max-parallel: 1
      fail-fast: false
      matrix:
        stream: ['charges', 'officers', 'persons-with-significant-control', 'persons-with-significant-control-statements', 'filings', 'companies', 'insolvency-cases', 'company-exemptions', 'disqualified-officers']

    steps:
      - name: Checkout repository
        uses: actions/checkout@v6

      - name: Use Bun
        uses: oven-sh/setup-bun@v2

      - name: Install dependencies
        run: bun install --frozen-lockfile
        working-directory: eventCapture

      - run: bun captureStream.ts ${{ matrix.stream }}
        working-directory: eventCapture

      - name: Install dependencies
        run: bun install --frozen-lockfile
        working-directory: historicalEvents

      - run: bun lakehouse.ts ${{ matrix.stream }}
        working-directory: historicalEvents

      - run: bun snapshots.ts ${{ matrix.stream }}
        working-directory: historicalEvents